\documentclass[a4paper]{report}

\usepackage{bbm}
\usepackage{bm}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{RJournal}
\usepackage{amsmath,amssymb,array}
\usepackage{booktabs}
\usepackage{float}
\usepackage[parfill]{parskip}
\usepackage[round]{natbib}
\usepackage{subfigure}

\setlength\parindent{0pt}

\begin{document}
\SweaveOpts{concordance=TRUE}

\sectionhead{Contributed research article}
\volume{XX}
\volnumber{YY}
\year{20ZZ}
\month{AAAA}

\begin{article}

\title{Walkr: A Sampling Solution to Matching Problems}

\author{by Yuanchu Dang}

\maketitle      

\abstract{
  Solve matching problems using uniform sampling. 
}


\section{Matching: Motivation and Formulation}

This section provides the motivation of a classical matching problem. Suppose we have a dataset that contains a response variable $Y$, a treatment variable $T$ and some other covariates represented by $X = (x_1, x_2, ..., x_t)$. Here, treatment is a categorical variable that indicates the membership of an observation in the treatment group or control group, and thus takes $0$ or $1$. Our goal is to investigate the effect of treatment $T$ on the response variable $Y$. To achieve this goal, we need to control for $X = (x_1, ..., x_t)$. In an ideal world where we can carry out our own experiment, we would like to randomly assign treatment to our sample. However, observational datasets happen more often than not, so such random assignment of treatment cannot be easily obtained. However, to simulate such random assignment, we can ``match'' each subject $t$ in the treatment group with a corresponding subject $c$ in the control group so that $c$ ``resembles'' $t$ in terms of $X = (x_1, ..., x_n)$. In some way, we have mimicked the simulation of a randomized blocked experiment. With these intuition, we formulate the matching problem as follows:

Given a data set of $n$ observations $D = \{(T_i, X_i, Y_i)\}_{i = 1}^n$ where $T_i$, $X_i$ and $Y_i$ respectively indicate the treatment variable, covariate and response variable for the i-th subject, we want to find a partition of $D$, denoted by a collection of subsets $\{S_j\}_{j = 1}^m$, such that the $X_i$ component of all $(T_i, X_i, Y_i) \in S_j$ are ``close'' for any fixed $j$.

\section{Gary King's Approach}

\subsection{Matching Methods}

King proposed and implemented many matching methods in his MatchIt package, which includes: exact matching, subclassification, nearest neighbor matching, optimal matching, full matching, genetic matching, and coarsened exact matching. Broadly speaking, these matching methods can be divided into two categories: the first category looks for a best match for each treated subject in the control group; the second category loosely puts ``similar'' observations (both treated and control) into a common ``subclass''. Most often, both approaches keep the maximum possible number of treated observations and drop unmatched control observations by assigning zero weights to them.

All these matching methods are nonparametric in the sense that they are free from model assumptions. Thus they introduce no further bias. However, we should note that matching is simply a form of data preprocessing. The bulk of the analysis has yet to be done after matching.

\subsection{Balance Statistic - Defining ``Similarity''}

To assess the goodness of a matching, one needs to know how ``close'' the covariate distributions are in the treated versus controlled groups. To do this, King defined a statistic called ``balance'', which is a synthesis of a bunch of information in itself. As King himself puts it, ``MatchIt provides a number of ways to assess the balance of covariates after matching, including numerical summaries such as the `mean Diff' (difference in means) or the difference in means divided by the treated group standard deviation, and summaries based on quantile-quantile plots that compare the empirical distributions of each covariate''. He also noted that balance diagnostics should be performed on all variables in $X$, even if some covariates are excluded from the matching procedures.

\section{CEM Paper Result Replication}

In this section, we are going to replicate the key result of Gary King's paper, which compares the performance of several matching methods with that of CEM. Comparisons are done in terms of biases, standard deviations, matching sizes, balances, and running times.

First we load the libraries and the working data set $DW$. $DW$ is a subset of LeLonde.

<<replicate1, eval=FALSE>>=
require(cem)
require(MatchIt)
require(Matching)
data(DW)
@

Then we separate the treated and control observations of $DW$, remove the original $treat$ from $DW$, and conduct a bunch of other preparatory calculations.

<<replicate2, eval=FALSE>>=
tsubjects <- which(DW$treated == 1)
csubjects <- which(DW$treated == 0)

# remove the treated variable (will be simulated later)
dati <- DW[,-c(1, 9)]

# Y - var
outcome <- DW$re78

# simulation: 5000 times
MCSim <- 5000

# num of treated
nt <- length(tsubjects)

# num of control
nc <- length(csubjects)

# num of total
n <- nt + nc

# treated: a vector of boolean
treated <- logical(n)
treated[tsubjects] <- TRUE

# force dati (with treated removed) to be numeric for regression purpose
dati.num <- dati
for(i in 1:dim(dati)[2]) dati.num[, i] <- as.numeric(dati[, i])
@

Now we want to set a vector of probabilities for the assignment of treatment to each of the $445$ subjects.

<<replicate3, eval=FALSE>>=
# use glm for a logistic regression
propensity  <- glm(treated ~ I(age^2) + I(education^2) + black +
                     hispanic + married + nodegree + I(re74^2) + I(re75^2) +
                     u74 + u75, family = binomial(link = "logit"), data = dati)
M <- cbind(rep(1, n),
           propensity$linear.pred,
           I(log(dati$age)^2),
           I(log(dati$education)^2),
           I(log(dati$re74 + 0.01)^2),
           I(log(dati$re75 + 0.01)^2))

# misspecified weights for: Intercept, linear.pred, age, educ, I(re74^2), and I(re75^2)
propensity.coeffs <- as.matrix(c(1.00, 0.5, 0.01, -0.3, -0.01, 0.01))

# mu: log odds
mu = M %*% propensity.coeffs

# Tr.pred: actual probability, through the logit transformation
Tr.pred <- exp(mu)/(1 + exp(mu))
TreatmentEffect <- 1000
TreatmentReal <- matrix(nrow = n, ncol = 1)
@

Then set up a series of containers for SATT, running times, sizes, L1 metrics and breaks.

<<replicate4, eval=FALSE>>=
# tmp stores the value of the simulation of each method
tmp   <- matrix(NA, MCSim, 6)
colnames(tmp) <- c("RAW", "MAH", "PSC", "GEN", "CEM", "CEM.W")

# times stores the running time of each method
times <- matrix(NA, MCSim, 4)
colnames(times) <- c("MAH", "PSC", "GEN", "CEM")

# sizes stores the matched treated/control # of each method
sizes <- matrix(NA, MCSim, 10)
colnames(sizes) <- c("RAW(nt)", "RAW(nc)",
                     "MAH(nt)", "MAH(nc)",
                     "PSC(nt)", "PSC(nc)",
                     "GEN(nt)", "GEN(nc)",
                     "CEM(nt)", "CEM(nc)")

# ELLE1 stores the L1 metric of each method
ELLE1 <- matrix(NA, MCSim, 5)
colnames(ELLE1) <- c("RAW", "MAH", "PSC", "GEN", "CEM")

# a list of breaks obtained from histogram
mybr = list(re74      = hist(dati$re74, plot = FALSE)$breaks, 
            re75      = hist(dati$re75, plot = FALSE)$breaks,
            age       = hist(dati$age, plot = FALSE)$breaks,
            education = hist(dati$education, plot = FALSE)$breaks)
@

Now simulate $5000$ times. For each iteration, assign treatment to the $445$ subjects according to the pre-calculated probabilities and calculate the $outcome$ by $$Y = 1000 \times T + 0.1 \times exp(0.7 \times log(re74 + 0.01 + 0.7 \times log(re75 + 0.01))) + \epsilon$$ where $\epsilon \sim N(0, 10)$. Then calculate and store the SATT, running time, size, L1-metric of each of the matching methods. Line-by-line comment as below.

<<replicate5, eval=FALSE>>=
# run the simulation for 5000 times
for(MC in 1:MCSim){
  
  # sample the treatment/control according to the pre-decided probability Tr.pred
  for(i in 1:n){
	  TreatmentReal[i] = sample(0:1, 1, prob = c(1 - Tr.pred[i], Tr.pred[i]))
	}
 
  # outcome assigns a treatment effect of 1000; error ~ N(0, 100)  
  outcome <- I(TreatmentEffect*TreatmentReal) +
    .1*exp(.7*log(dati$re74+0.01) + .7*log(dati$re75+0.01)) + rnorm(n, 0, 10)
  
  # separate treated from control
  treated <- TreatmentReal
  tsubjects <- which(TreatmentReal==1)
  csubjects <- which(TreatmentReal==0)
  nt <- length(tsubjects)
  nc <- length(csubjects)
  
  # use the simulated treat vector (as opposed to the original treatment indicator in LeLonde!)
  dati1 <- data.frame(treat = treated, dati)
  
  # raw L1 (which measures the balancing)
  L1.raw <- L1.meas(treated, dati, breaks = mybr)$L1
  
  ################# CEM ###################
  # result and running time
  system.time(cem.mat <- cem("treat", dati1))[3] -> t.cem
  
  # matched treated and control
  cem.tr <- which(cem.mat$groups == "1" & cem.mat$matched == TRUE)
  cem.ct <- which(cem.mat$groups == "0" & cem.mat$matched == TRUE)
  
  # L1
  cem.idx <- unique(c(cem.tr, cem.ct))
  L1.cem <- L1.meas(treated[cem.idx], dati[cem.idx,], breaks = mybr)$L1
  
  ################# MAH ###################
  # result and running time
  system.time(mah.mat <- Match(Tr = treated,
                               X = dati,
                               Weight = 2,
                               M = 1,
                               replace = FALSE))[3] -> t.mah
  
  # matched treated and control
  mah.tr <- mah.mat$index.treated
  mah.ct <- mah.mat$index.control
  
  # L1
  mah.idx <- unique(c(mah.tr, mah.ct))
  L1.mah <- L1.meas(treated[mah.idx], dati[mah.idx,], breaks = mybr)$L1

  ########## Propensity Score ##############
  # result and running time
  # first step: run a logistic regression
  system.time(pscore  <- glm(treated~
                               age + education + re74 +
                               re75 + black + hispanic +
                               nodegree + married +
                               u74 + u75,
                             family = binomial(link = "logit"),
                             data = dati1))[3] -> t.psc1
  
  # second part: match according to the result
  system.time(psc.mat <- Match(Tr = treated,
                               X = pscore$fitted,
                               M = 1,
                               replace = FALSE))[3] -> t.psc2
  
  # running time should be the sum of both steps
  t.psc <- t.psc1 + t.psc2
  
  # matched treated and control
  psc.tr <- psc.mat$index.treated
  psc.ct <- psc.mat$index.control
  
  # L1
  psc.idx <- unique(c(psc.tr, psc.ct))
  L1.psc <- L1.meas(treated[psc.idx], dati[psc.idx,], breaks = mybr)$L1
  
  ############ Genetic Match ###############
  # result and running time
  system.time(gen1 <- GenMatch(X=dati, Tr=treated))[3] -> t.gen
  mgen1 <- Match(Y = outcome, Tr = treated, X = dati, Weight.matrix = gen1)
  
  # matched treated and control
  gen.tr <- unique(gen1$matches[,1])
  gen.ct <- unique(gen1$matches[,2])
  
  # L1
  gen.idx <- unique(c(gen.tr, gen.ct))
  L1.gen <- L1.meas(treated[gen.idx], dati[gen.idx,], breaks = mybr)$L1
  
  ############## Comparison ###############
  # compare sizes
  nt.cem <- length(unique(cem.tr))
  nc.cem <- length(unique(cem.ct))
  nt.mah <- length(unique(mah.tr))
  nc.mah <- length(unique(mah.ct))
  nt.psc <- length(unique(psc.tr))
  nc.psc <- length(unique(psc.ct))
  nt.gen <- length(unique(gen1$matches[,1]))
  nc.gen <- length(unique(gen1$matches[,2]))
  sizes[MC,] <-  c(nt, nc,
                   nt.mah, nc.mah,
                   nt.psc, nc.psc,
                   nt.gen, nc.gen,
                   nt.cem, nc.cem)
  
  # compare SATT estimation
  RAW <- mean(outcome[tsubjects]) - mean(outcome[csubjects])
  CEM <- mean(outcome[cem.tr]) - mean(outcome[cem.ct])
  CEM.W <- weighted.mean(outcome[cem.tr], cem.mat$w[cem.tr]) -
    weighted.mean(outcome[cem.ct], cem.mat$w[cem.ct])
  MAH <- mean(outcome[mah.tr]) - mean(outcome[mah.ct])
  PSC <- mean(outcome[psc.tr]) - mean(outcome[psc.ct])
  GEN <- mgen1$est
  tmp[MC,] <- c(RAW, MAH, PSC, GEN,  CEM, CEM.W)
  
  # compare L1
  ELLE1[MC,] <- c(L1.raw, L1.mah, L1.psc, L1.gen, L1.cem)
  
  # compare running time
  times[MC,] <-  c(t.mah, t.psc, t.gen, t.cem)
}

# calculate bias
bias <- colMeans(tmp,na.rm=TRUE)-1000

# Average std.dev
std.dev <- apply(tmp, 2, function(x) sd(x, na.rm = TRUE))

# RMSE
RMSE <- sqrt(colMeans((tmp - 1000)^2, na.rm = TRUE))

# Average running time
runtime <- colMeans(times,na.rm=TRUE)

# average L1 balancing
colMeans(ELLE1, na.rm = TRUE)

# Average Matched units
size <- colMeans(sizes, na.rm = TRUE)
@

\section{Using MatchIt}

This section provides a guide the usage of King's $MatchIt$ package. For illustration, we will use the Lalonde dataset. First load the data with

<<r1, eval=TRUE>>=
library(MatchIt)
data(lalonde)
@

The main method in $MatchIt$ is $matchit$. Suppose we want to match the dataset on covariates $age$ and $educ$. Then we should call the following instruction. Note that $treat$ is our treatment variable here, and that during the matching process, we should not be concerned about the response variable (which is $re78$ in Lalonde) at all.

<<r2, eval=TRUE>>=
m.out <- matchit(treat ~ age + educ, method = "exact", data = lalonde)
@

After per matching, we shoud check balance diagnostics with $summary$.

<<r3, eval=FALSE>>=
summary(m.out)
@

Notice that $matchit$ is a very nasty objects, but it can be further cleaned up by $match.data$.

<<r4, eval = TRUE>>=
m.data <- match.data(m.out)
@

In the code above, the returned value $m.data$ is simply the original lalonde data frame with two additional columns: $weights$ and $subclass$. Observations with the same $subclass$ label belong to the same subgroup, and within each subgroup, proportional $weights$ are assigned to treated and control observations so that treated and control observations have roughly the same ``presence''.

Then, King proposed using his Zelig package for the bulk of the analysis. Below, we fit a least square model and check out the mean difference in response between treated and controlled members.

<<r5, eval = TRUE>>=
library(Zelig)
z.out <- zelig(re78 ~ treat + age + educ, data = m.data, model = "ls")
x.out <- setx(z.out, treat = 0)
x1.out <- setx(z.out, treat = 1)
s.out <- sim(z.out, x = x.out, x1 = x1.out)
summary(s.out)
@


\section{The Walkr Approach}

\end{article}
\end{document}