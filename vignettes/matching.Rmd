---
title: 'Discussion: Matching and Sampling'
author: "Yuanchu Dang"
date: "December 23, 2015"
output: html_document
linestretch: 1.5
header-includes:
- \usepackage{bbm}
- \usepackage{amsfonts}
- \usepackage{bm}
---

1. Matching: Motivation and Formulation
=======================================

This section summarizes the motivation of a classical matching problem. Suppose we have a dataset that contains a response variable $Y$, a treatment variable $T$ and some other covariates represented by $X = (x_1, x_2, ..., x_t)$. Here, treatment is a categorical variable that indicates the membership of an observation in the treatment group or control group, and takes $0$ or $1$. Our end goal is to investigate the effect of treatment $T$ on the response variable $Y$. However, this is not doable unless we control for $X = (x_1, ..., x_t)$. In an ideal world where we can carry out experiment, we would want to compare two subjects with different $T$ but exactly the same $X$. However, observational datasets happen more often than not, so such variate control cannot be easily obtained. Therefore, we need to "match" each treated subject $x$ with a corresponding subject $x'$ in the control group that "resembles" $x$ in terms of $X = (x_1, ..., x_n)$. In some way, matching is similar to the simulation of a randomized blocked experiment. With these intuition, we formulate the matching problem as follows:

Given a data set $D$ of $n$ observations, denote each observation by $(T_i, X_i, Y_i)$ ($i = 1, 2, ..., n$) where $T_i$, $X_i$ and $Y_i$ respectively indicate the treatment variable, covariate and response variable for the i-th subject. We want to find a partition of $D = \{(T_i, X_i, Y_i)\}_{i = 1}^n$, denoted by a collection of subsets $\{S_j\}_{j = 1}^m$ such that $\{(T_i, X_i, Y_i) \ | \ T_i = 1\} \subset \cup_{j = 1}^m S_i$, and that the $X_i$ component of all $(T_i, X_i, Y_i) \in S_j$ are "similar" for any fixed $j$.

2. Gary King's Approach
========================

## 2.1 Matching MethodS

King proposed and implemented many matching methods in his MatchIt package, which includes: exact matching, subclassification, nearest neighbor matching, optimal matching, full matching, genetic matching, and coarsened exact matching. Broadly speaking, these matching methods can be divided into two categories: the first category looks for a best match for each treated subject in the control group; the second category loosely puts ``similar'' observations (both treated and control) into the same "subclass". Most often, both approaches keep the maximum possible number of treated observations and drop unmatched control observations by assigning zero weights to them.

## 2.2 How to Define ``Similarity''?

King defined a statistic called "balance", which is a synthesis of a bunch of information in itself. To assess the goodness of a matching, one needs to know how close the covariate distributions are in the treated versus controlled groups. As King himself puts it, "MatchIt provides a number of ways to assess the balance of covariates after matching, including numerical summaries such as the `mean Diff' (difference in means)
or the difference in means divided by the treated group standard deviation, and summaries based on quantile-quantile plots that compare the empirical distributions of each covariate". He also noted that balance diagnostics should be performed on all variables in $X$, even if some covariates are excluded from the matching procedures.

## 2.3 Highlights

All these matching methods are nonparametric in the sense that they are free from model assumptions. Thus they introduce no further bias. However, we should note that matching is simply a form of data preprocessing. The bulk of the analysis has yet to be done after matching!

3. Playing Around with MatchIt
==============================

Lalonde dataset will be our major toy. First load the data with

```{r1, eval = TRUE}
library(MatchIt)
data(lalonde)
```

The main method in King's package is $matchit$. Suppose we want to match the dataset on covariates $age$ and $educ$. Then we should call the following function. Note that $treat$ is our treatment variable here, and that during the matching process, we should not be concerned about the response variable (which is $re78$ in Lalonde) at all.

```{r2, eval = TRUE}
m.out <- matchit(treat ~ age + educ, method = "exact", data = lalonde)
```

After per matching, $summary$ can be used to check balance diagnostics.

```{r3, eval = TRUE}
summary(m.out)
```

Notice that $matchit$ is a very nasty objects, but it can be further cleaned up by $match.data$. In the code below, the returned value $m.data$ is simply the original lalonde data frame with two additional columns: $weights$ and $subclass$.

```{r4, eval = TRUE}
m.data <- match.data(m.out)
```

Then, King proposed using his Zelig package to do the main analysis. Here we fit a least square model and check out the mean difference in response between treated and controlled members.

```{r5, eval = TRUE}
library(Zelig)
z.out <- zelig(re78 ~ treat + age + educ, data = m.data, model = "ls")
x.out <- setx(z.out, treat = 0)
x1.out <- setx(z.out, treat = 1)
s.out <- sim(z.out, x = x.out, x1 = x1.out)
summary(s.out)
```


4. Connection with the Sampling Problem and Walkr
=================================================

## 4.1 Weights in MatchIt v.s. Walkr?

## 4.2 I Just Want to Use Walkr Somehow!





